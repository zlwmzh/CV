一. Stage_1 Classes_classification 文件夹下各文件说明
   1. Classes_classification.py 主文件，训练和验证模型需要运行此文件
   2. Classes_make_anno.py 数据处理文件；将二进制文件转换为训练集的特征数据,目标属性数据以及验证集的特征属性数据和目标属性数据
   3. Classes_Network.py 神经网络文件；这里我构建了Resnet50网络结构
   4. Classes_test.py 测试文件；取Datas中的test中的图片文件，进行预测分类
   5. Classes_train_features.npy 训练集特征属性，其实就是每张图片的向量
   6. Classes_train_labels.npy 训练集目标属性
   7. Classes_val_features.npy 验证集特征属性，其实就是每张图片的向量
   8. Classes_val_labels.npy 验证集目标属性
   9. 动物纲类模型训练日志：每个epoch都会进行本地日志存储
   10. modesl 文件夹：每完成一个epoch，都会进行一次模型存储。此文件夹就是存储模型的

二. Classes_Network.py 说明
    1. 定义占位符。 这里我完全是按照论文上定义的输入图片224*224*3的大小
       input_x: 输入图片占位符
       input_y: 图片标签占位符
       self.training: BP进行操作时是否对里面的两个参数进行训练; 因为训练时我们需要训练，而进行验证时则不需要
       self.keepdrop: 为防止过拟合，我在网络结构中进行了多次Dropout; 同时也是因为时训练时需要，验证时不需要
       self.lr: 学习率
    2. 构建网络结构。 这里我用到了ResNet 50网络结构。
       a. conv1:
          对224*224*3的图片进行kernel为 64*7*7*3，stride为2进行卷积，图片缩放为128*128*64；
          然后进行一次BP操作,relu进行激活，在进行一次最大池化3*3,stride=2， 图片大小为56*56*64，最后进行以下dropout操作
       b. conv2:
          进行3次1*1，3*3和1*1的卷积操作。可详见代码。处理后图片的大小为56*56*256
       c. conv3:
          进行4次1*1，3*3和1*1的卷积操作。可详见代码。处理后图片的大小为28*28*512
       d. conv4:
          进行6次1*1，3*3和1*1的卷积操作。可详见代码。处理后图片的大小为14*14*1024
       e. conv5:
          进行3次1*1，3*3和1*1的卷积操作。可详见代码。处理后图片的大小为7*7*2048
       f. fc1:
          进行一次全连接
       g. out:
          进行一次全连接，然后经过softmax激活
       h. 计算损失：交叉熵损失函数
       i. 定义优化器
       j. 计算准确率
       k: 一些参数的赋值